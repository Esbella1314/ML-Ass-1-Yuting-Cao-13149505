{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "A1_ReportDraft.ipynb",
      "version": "0.3.2",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgqWnaYlNr0c",
        "colab_type": "text"
      },
      "source": [
        "# Review Report on \"Bayesian Networks\"\n",
        "\n",
        "[Link to Notebook Version of This Report](https://colab.research.google.com/github/Esbella1314/ML-Ass-1-Yuting-Cao-13149505/blob/master/A1_ReportDraft.ipynb#scrollTo=qgqWnaYlNr0c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMIr6dJ8N33z",
        "colab_type": "text"
      },
      "source": [
        "Subject Name:\t\t32513 Machine Learning\n",
        "\n",
        "Students Name:     Yuting Cao                   \n",
        "Student ID:        13149505                \n",
        "Student Email:     yuting.cao@student.uts.edu.au\n",
        "\n",
        "\n",
        "Github Link: https://github.com/Esbella1314/ML-Ass-1-Yuting-Cao-13149505/blob/master/A1_ReportDraft.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDOKSARXNr0d",
        "colab_type": "text"
      },
      "source": [
        "## 1 Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxSQcnN2NyiG",
        "colab_type": "text"
      },
      "source": [
        "Bayesian belief networks is also called reliability network. It’s the extension of Bayesian method, it’s a very effective theory model in inference domain and to explain the unsure knowledge. It’s a natural and efficient method for representing probabilistic dependencies among a set of variables [1]. \n",
        "\n",
        "Although Bayesian belief networks is a very complicated algorithm, but it still reduces the big amount of calculation work which increase the efficiency a lot.\n",
        "\n",
        "This paper is using Bayesian belief networks to solve the probabilistic inference problem with a high-quality result. This article chooses the 3SAT as an example to explain how to use belief networks to transform this NP-Complete problem to NP-Hard to solve the probabilistic inference problem. The author has showed the processes how to transform the 3SAT problem to NP-Hard, and at the end of this paper, the author also proved that the NP-Complete problem has been transformed to NP-hard.\n",
        "\n",
        "However, there is no any algorithm which can fit all the problems, for different cases, we will need to find the most suitable and effective algorithm to solve the problems.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtTa57trNr0e",
        "colab_type": "text"
      },
      "source": [
        "##2 Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxWTSavyOpq3",
        "colab_type": "text"
      },
      "source": [
        "The research is about introducing how to use Bayesian belief networks in probabilistic inference. A theorem has been proved that the 3SAT problem has been transformed from NP-Complete to NP-Hard through Bayesian belief networks algorithm. \n",
        "\n",
        "##**2.1 Bayesian Belief Networks**\n",
        "\n",
        "Bayesian belief networks is made by directed acyclic graph (DAG) and conditional probability table (CPT) [2]. The DAG contains the node variables and directed edges which connect those node variables. The node variables stand for random variables, the directed edges stand for the relationships between those node variables (The parent node points to the children node points), and the conditional probability means the relationship strength between node variables, if there is no parent node variable, then represent by priori probability. Those node variables can be any abstract problem.\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/Esbella1314/ML-Ass-1-Yuting-Cao-13149505/blob/master/download.jpg?raw=true\" width=\"300\"/>\n",
        " \n",
        " Figure 1: Directed Acyclic Graph\n",
        " \n",
        " From the figure 1 as above, we can see that even if an arc from node a or b to a node c usually means that c is caused by a and b, it's not just one possibility to explain the arcs in Bayesian networks. So, Bayesian networks can represent not only causal relationships but some other relationships as well. The Bayesian networks represent for the rule-based systems of probabilistic.\n",
        "Bayesian belief network has a great function on reducing assessing and storing the amount of probabilities. Bayesian is the algorithm which can explain the conditional probability and edge probability.\n",
        "This article will only discuss the probabilities when Y=T, not need to consider about the situation such as Y=F.\n",
        "\n",
        "##**2.2 The Definition of 3SAT**\n",
        "\n",
        "This article is using 3SAT as an example, trying to transform this problem from NP-complete to NP-hard problem.\n",
        "As you can see that the 3SAT has three levels which are U, C, D. Every C is satisfactory or not depends on the a few corresponding U variables. Then the final Y is Ture or False based on both the corresponding C and U variables. Here in the figure 2, every clause $c_i$ includes a disjunction of three U.\n",
        "\n",
        "<img src=\"https://github.com/Esbella1314/ML-Ass-1-Yuting-Cao-13149505/blob/master/12.png?raw=true\" width=\"800\"/> \n",
        "\n",
        "Figure 2: 3SAT Directed Acyclic Graph\n",
        "\n",
        "The 3SAT problem involves a few collections, the values are set as Boolean variables (True and False), we record them as C = {$c_1$,$c_2$, …,$c_m$}, U = {$u_1$,$u_2$, …,$u_n$}. ¬c and c are literals over C, c stands for true(T) while ¬c stands for false(F). Similarly, ¬u and u are both literals over U, and u stands for true (T) while ¬u stands for false (F).\n",
        "\n",
        "###**2.2.1 Set Collections for U and C**\n",
        "\n",
        "Please see the u and c relationship example in table 1 as below:\n",
        "\n",
        "* $c_1$=($u_1$∪$u_2$∪$u_3$)\n",
        "  \n",
        "Node Variables|$c_1$|$¬u_1$|$¬u_2$|$¬u_3$\n",
        "----------------|----|---|----|-------\n",
        "Boolean Result|T   |T   |F    |T\n",
        "\n",
        "Table 1: u and c Relationship Example\n",
        "\n",
        "Every C is connected with a few U, only when all the U which connect with C are satisfiable, the corresponding C will be satisfiable as well. The 3SAT problem here is making decision about whether there is a set of collections U can satisfy all the clauses in C as well. Please see the example in table 2 as below:\n",
        "\n",
        "\n",
        "* U={$u_1$,$u_2$,$u_3$,$u_4$}\n",
        "  \n",
        "* C={($u_1$∪$u_2$∪$u_3$),($¬u_1$∪$¬u_2$∪$u_3$),($u_2$∪$¬u_3$∪$u_4$)}\n",
        "\n",
        "\n",
        "Node Variables|$u_1$|$u_2$|$u_3$|$u_4$\n",
        "--------------|----|---|----|-------\n",
        "Boolean Result|  T   |F   |F    |T\n",
        "Node Variables|  $u_1$∪$u_2$∪$u_3$|$¬u_1$∪$¬u_2$∪$u_3$|$u_2$∪$¬u_3$∪$u_4$|C\n",
        "Boolean Result| T   |F   |F  |T    \n",
        "\n",
        "Table 2: U and C Relationship Example\n",
        "\n",
        "###**2.2.2 Set Collections for $U_α$ and $C_β$**\n",
        "\n",
        "Define $U_α$ to be the $α^{th}$ variable among the whole set of U, and α belongs to 1≤ i ≤ n. When $ u_i$= T, the corresponding ith digital of binary is 1, to the contrary, when $u_i$= F, the corresponding ith digital of binary is 0. $U_S$ means the all the variables in U satisfy C.$ C_s$  means that for every variable$ C_j$, the value is T, and β belongs to 1≤j≤m. $C_β$ stands for the $β^{th}$ variable among the whole set of $C_j$, and is defined analogously to $U_α$.\n",
        "\n",
        "α,β are using the binary way to record the data. The order is from right to left.\n",
        "$U_α$, 1≤i≤n, for instance, $U_5$ stands for 0101, which is$u_1$ = T,$u_2$= F,$u_3$ = T, $u_4$ = F.\n",
        "$C_β$, 1≤j≤m, it’s similar to $U_5$, when it’s $C_5$, it means that the binary is 0101 as well. Please see the table 3 for the details as below \n",
        "\n",
        "Variables|$u_1$|$u_2$|$u_3$|$u_4$|Total\n",
        "--------------|----|---|----|-------|----\n",
        "Booleans|  T   |F   |T   |F|\n",
        "Binary|$2^0$|$2^1$|$2^2$|$2^3$|\n",
        "Calculation| 1  |0 |1|0  |5\n",
        "\n",
        "Table 3: $U_5$ Binary Example\n",
        "\n",
        "##2.3 Probabilistic Inference \n",
        "\n",
        "The phrase probabilistic inference using belief networks typically has been used to mean the calculation of P(A|B) [3].\n",
        "Generally, event A’s the probability while B happening is different from event B’s probability while A happening, however, those two have some connections, the formula is as below:\n",
        "\n",
        "* P(A|B) = P(A) P(B/A) / P(B)\n",
        "\n",
        "* P(A|B): Event A’s probability when the condition is that B happened already. P(A/B) is called event A’s posterior probability.\n",
        "\n",
        "* P(B|A): Similarly, P(B|A) means event B’s probability when the condition is that A has happened, the conditional probability of event B, and P(B|A) is also called event B’s posterior probability.\n",
        "\n",
        "* P(A): Event A’s edge probability or priori probability, it’s called priori because it doesn’t need to consider any factor about event B. \n",
        "\n",
        "* P(B): Similarly, this is called event B’s edge probability or priori probability. It’s always used as normalized constant as well.\n",
        "\n",
        "* P(B|A)/P(B) is always named standardized likelihood.\n",
        "\n",
        "In summary, Bayesian algorithm formula is as below:\n",
        "\n",
        "* Posterior Probability = (Similarity * Priori Probability) / Normalized Constant\n",
        "* Posterior Probability = Standardized Likelihood * Priori Probability \n",
        "\n",
        "If the propositional variable Y does not have any clear conditional information or task to determine P (Y = T), the form of probabilistic inference results will be very restricted. In this paper, all the probabilistic inference with other forms are general calculations of P (Y= T). \n",
        "\n",
        "In order to prove that calculating P (Y= T) is NP-hard, the author proves that the other probabilistic inference with more generalization forms are NP-hard problems too in this paper.\n",
        "\n",
        "##**2.4 Bayesian Networks Formulas for 3SAT**\n",
        "\n",
        "Step1: Set collections for C and U variables\n",
        "The 3SAT problem involves a few collections, the values are set as Boolean variables (True and False), we record them as C = {$c_1$,$c_2$, …,$c_m$}, U = {$u_1$,$u_2$, …,$u_n$}. ¬c and c are literals over C, c stands for true(T) while ¬c stands for false(F). Similarly, ¬u and u are literals over U, and u stands for true(T) while ¬u stands for false(F).\n",
        "\n",
        "*  U = {$u_1$, $u_2$, …, $u_n$}\n",
        " \n",
        "* C = {$c_1$, $c_2$, …, $c_m$}\n",
        "  \n",
        "When P(Y=T) > 0, PIBNETD comes out with the result ‘Yes’\n",
        "When P(Y=T) ≤ 0, PIBNETD comes out with the result ‘No’\n",
        "\n",
        "\n",
        "Step 2: Set probabilities for node variables and directed edges\n",
        "There are different probabilities stand for the different node variables and directed edges. Recording the Bayesian Network as BN which is represent as (V, A, P), V stands for a set of nodes or vertices. A stands for a set of arcs between different variables, P stands for a set of probabilities for different variables.\n",
        "BN = (V, A, P)\n",
        "\n",
        "* V = $V^t$∪$V^s$∪$V^o $  (Overall-Satisfaction-Testing$A^o $  ,$V^o $  $P^o $ , o means Overall)\n",
        "\n",
        "* A = $A^s$∪$A^o $      (Satisfaction-setting $A^s$ , $V^s$ ,$P^s$ , s means Satisfactory)\n",
        "\n",
        "* P = $P^t$∪$P^s$∪$P^o $  (Truth-setting $V^t$ ,$P^t$ ,t means True)\n",
        "\n",
        "* $V^t$ = U = {$u_1$, $u_2$, …, $u_n$},\n",
        "\n",
        "* $P^t$ = {P ($u_1$ = T) = 1/2, P ($u_2$ = T) = 1/2,…, P ($u_n$ = T) = 1/2}\n",
        "So, we could get the formula as below:\n",
        "\n",
        "* BN = ($V^t$ ∪$V^s$∪$V^o $, $A^s$∪$A^o $, $P^t$∪$P^s$∪$P^o $ ) \n",
        "\n",
        "\n",
        "Step 3: Set probabilities for node variables and directed edges when they are true or satisfactory\n",
        "\n",
        "For each clause $C_j$ ∈ C, and 1≤ j ≤m, ($V^s_j$, $A^s_j$ , $P^s_j$) is the clause-satisfaction-testing sub-component, it can distinguish if a variable in U satisfies clause $C_j$ in C or not. The formulas are as below:\n",
        "\n",
        "* $V^s_j$ = {$W^1_j$,$W^2_j$, $W^3_j$ ,$C_j$}\n",
        "\n",
        "* $A^s_j$ = {($W^1_j$,$C_j$), ($W^2_j$,$C_j$), ($W^3_j$,$C_j$)}\n",
        "\n",
        "* $P^s_j$ = {P ($C_j$ = T/$π_C$$_j$)}\n",
        "\n",
        "* P($C_j$= T/$π_C$$_j$) =1,when $g_j$($π_C$$_j$)=T\n",
        "\n",
        "* P($C_j$= T/$π_C$$_j$) =0,when $g_j$($π_C$$_j$)=F\n",
        "\n",
        "$W^1_j$ stands for the first literal in the corresponding $C_j$, and $W^2_j$, $W^3_j$  stand for the second and third literals in the corresponding $C_j$, for example: $V^s_3$ = {$u_2$,$ u_3$, $u_4$, $C_3$}, $C_3$ is directly connected with $u_2$,$ u_3$, $u_4$, which can decide is $C_3$ could be T or F.\n",
        "\n",
        "* $V^s$=$⋃^m_(j=1)$$V_j^s$ =$⋃^m_(j=1)${{$W^1_j$,$W^2_j$, $W^3_j$ ,$C_j$}\n",
        "\t\n",
        "* $A^s$=$⋃^m_(j=1)$$A_j^s$ = $⋃^m_(j=1)${($W^1_j$,$C_j$), ($W^2_j$,$C_j$), ($W^3_j$,$C_j$)}\n",
        "\n",
        "* $P^s$=$⋃^m_(j=1)$$P_j^s$  =$⋃^m_(j=1)$ {P ($C_j$ = T/$π_C$$_j$)}\n",
        "\n",
        "($V^s$, $A^s$,$P^s$) is made up of the set of the clause satisfaction-testing subcomponent s corresponding to each clause $C_j$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZLX6ZGVNr0f",
        "colab_type": "text"
      },
      "source": [
        "## 3 Innovation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmtyaOfDNr0g",
        "colab_type": "text"
      },
      "source": [
        "This paper talks about the 3SAT is a NP-Complete problem, which requires a lot of time and efforts to find the answer. So, the biggest innovation in this paper is the author uses the Bayesian network to complete the transformation of a famous 3SAT (NP-complete problem) to a NP-Hard by using Bayes Networking. The whole process is to transform the NP-Complete problem to PIBNETD (PIBNETD shorts for to Probabilistic Inference using Belief networks), then transform the PIBNETD(returns with decision) to the PIBNET (returns with probability). At the same time, there is another innovation is that by using Bayesian network saves a lot time to do plenty of data inferences.\n",
        "\n",
        "##**3.1 3SAT NP-Complete Problem is Transformed to NP-Hard**\n",
        "\n",
        " *NP: Short for non-deterministic. It can use polynomial time complexity algorithm to verify if an answer is correct or not.\n",
        " \n",
        " *NP-Hard: Short for non-deterministic polynomial-hard. It’s the most effective algorithm doesn’t exist for this kind of problems, which means can’t get the accurate result but a quite correct answer by using maximum likelihood. All the NP problems can reduce to NP-Hard.\n",
        " \n",
        " *NP-Complete: Short for non-deterministic polynomial-complete. It’s the hardest decision problem among the NP problems.\n",
        " \n",
        "α,β are using the binary way to record the data, please see the formulas as below: \n",
        "\n",
        "* $P (Y=T) = ∑^{2^n-1}_{α=0}∑^{2^m-1}_{β=0}P(Y=T/C_β)P(C_β/U_α)P(U_α)$\n",
        "\n",
        "* P(Y=T/$C_s$) P ($C_s$/$U_s $)P($U_s$)  (Satisfaction-setting $C_s$,$U_s$, s means Satisfactory)\n",
        "\n",
        "* P(Y=T) ≥ P (Y=T/$C_s$) P ($C_s$/$U_s$)P($U_s$)\n",
        "\n",
        "* P(Y=T/$C_s$)=1 \n",
        "\n",
        "* P($U_s$)= $(1/2)^n$\n",
        "\n",
        "* P($C_s$/$U_s$) >0\n",
        "\n",
        "* P($C_s$/$U_s$) = P ($C_1$= T/$W^1_1$,$W^2_1$, $W^3_1$)...P($C_m$ = T/$W^1_m$, $W^2_m$,$W^3_m$)\n",
        "\n",
        "\n",
        "$U_s$ stands a for a set of satisfiable clauses C, at the same time, in this situation, it means that every clause $c_j$  satisfies truth assignment in C. So, we can get the formulas as below:\n",
        "\n",
        "* P($C_j$ = T/ $W^1_j$,$W^2_j$, $W^3_j$) = 1, 1≤j≤m\n",
        "\n",
        "* P($C_s$/$U_s$) = 1\n",
        "\n",
        "* P(Y=T) >0\n",
        "\n",
        "So we can see that P ($C_s$/$U_α$) = 0 for all Uα and when $C_β$ ≠ $C_s$, P (Y=T/$C_β$) = 0, which means P(Y=T) = 0, this can prove that PIBNETD is transferred into PIBNET, and this also means that PIBNET is NP-hard.\n",
        "\n",
        "##**3.2 Bayesian Networks Reduce Calculation**\n",
        "\n",
        "Although Bayesian belief networks is a very complicated algorithm, but it still reduces the big amount of calculation work which increase the efficiency.\n",
        "\n",
        "When use Bayesian network in the joint probability, all the variables in every example can be set as there are n probabilities. We do not need to calculate the 2n probabilities in the joint probability space when using Bayesian network in joint probability but just calculate the n variables from each example in the network. \n",
        "\n",
        "By using Bayes belief network, it will not need to conculcated 2n times to get all the probabilities but just need to find out some probabilities when some conditions are already set to be T or F. This algorithm saves a lot of time and still get a very accurate result.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1NMOEJbNr0h",
        "colab_type": "text"
      },
      "source": [
        "## 4 Technical Quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1OXyr0wNr0h",
        "colab_type": "text"
      },
      "source": [
        "If the full score is 10, I would like to give this paper an 8. Overall, the technical development quality of this article is quite high. 3SAT is a very famous NP-complete problem, there are many people have had done researches on it. Using the Bayesian belief networks to solve the probabilistic inference problem is very efficient. \n",
        "In the paper, the author comes up with a solution to solve the 3SAT problem by using Bayesian networks, and there are many formulas and examples in this paper to support the points which helps me understand how the Bayesian networks apply on the 3SAT NP-Complete problem., \n",
        "\n",
        "However, the orders of the content are a bit messy, it didn’t follow up a clear structure when give the formulas and state the content, quite hard for me to put everything together easily and understand things well. Also the formulas are too many and been explained the same thing again and again. I guess the author wants to make sure the readers can understand his article well that’s why he always tries to explain the same things couple times, but this makes the article very massive and even make me feel confused and worried about missing any information he is giving, but actually there are just many things are being told over again and again which wastes time. \n",
        "\n",
        "What’s more, there are many things haven’t been explained such as what’s NP-Complete, NP-Hard problems and etc., so I have to do a lot of extra researches to help me understand the article, even if the author has put some references to show me that I could refer to some other resources, but it takes a bit longer time for me to combine the knowledge I learn from other articles with this one and understand the article.\n",
        "\n",
        "As a whole, this paper has come up a solution for a very famous NP-Complete problem through Bayesian network which is great but maybe organize the content better and give more explanations in the article will be more helpful for readers to understand the article."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsWQAfF6Nr0i",
        "colab_type": "text"
      },
      "source": [
        "## 5 Application and X-factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUdAjwtrNr0k",
        "colab_type": "text"
      },
      "source": [
        "The author solves the 3SAT probabilistic inference problem efficiently through certain restricted kind of Bayesian networks and the author proved that the PIBNET is NP-hard. \n",
        "\n",
        "The Bayesian belief networks can be used among many different relationships. Moreover, it represents the probabilistic relationships explicitly. And in the Bayesian belief networks just need to make consideration about the dependencies among variables in a domain which are already known, no need to know all variables which rely on other variables. \n",
        "\n",
        "The Bayesian belief networks can be used to express and analyze unsure and probabilistic events, apply on the decisions which conditionally rely on multiple control variables, the inference can be got from the missing, inaccurate or unsure information.\n",
        "\n",
        "Bayesian Network can be applied in many domains such as gaming and law, bioinformatics, image processing, protein structure, document classification, gene regulatory networks, decision support systems, engineering, gene expression analysis, medicine, information retrieval, computational biology, data fusion, etc. \n",
        "There is no ideal condition, in the real world, the relationships are more complicated, it always requests a large and complex connected network. Since there is no any general or exact algorithm can fit all the problems, so we face different problems especially the complicated problems, we need to analyze the problem, to approach a more accurate result, we should find the most suitable algorithms for the corresponding problems. \n",
        "There is average-case algorithms we can use, but also when there are some special or complicated problems, here are many different algorithms we can consider as well such as approximation algorithms and special-case algorithms.\n",
        "\n",
        "Approximation algorithms produce an inexact, bounded solution, but guarantee that the exact solution is within those error bounds [4].\n",
        "\n",
        "Special-case algorithms are capable of efficient probabilistic inference for special types of belief networks [5].\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNkVFTsENr0m",
        "colab_type": "text"
      },
      "source": [
        "## 6 Presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1Y1g5KuNr0n",
        "colab_type": "text"
      },
      "source": [
        "The overall structure is good, very clear about what’s the author’s opinions and what’s the article is about, but I find that it is still a bit difficult to read, the author uses very complicated words or sentences to explain things and sometimes explain the same thing over again and again which makes the article a but messy.\n",
        "\n",
        "It’s very hard for me to understand this article in the beginning, there are some important words such as NP-Complete and NP-Hard are not explained, as well as some other resource are put as references which make it more complicated to go through everything and understand what’s the author tries to tell us.\n",
        "\n",
        "Also, because the content is a little messy, I work hard on collecting information and putting them together to understand how the Bayesian network applies on the 3SAT and how the formulas work.\n",
        "\n",
        "So I can present the main ideas of this paper since the information and examples are very sufficient, but some details are a bit hard to sort them out and totally understand, if the authors could have organized the content better and give some explanations directly in the paper will make the presentation much easier and better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oap8U2O8Nr0n",
        "colab_type": "text"
      },
      "source": [
        "## 7 References\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy65-_N4Lnk3",
        "colab_type": "text"
      },
      "source": [
        "[1] Cooper, G. 1990, ‘The Computational Complexity of Probabilistic Inference Using Bayesian Belief Networks’, Artificial Intelligence, Vol. 42, Issues no. 2–3, pp. 393.\n",
        "\n",
        "[2] Charles Elkan(2012), Bayesian networks, University of California Computer Science and Engineering, United States, viewed 28 August 2019, https://cseweb.ucsd.edu/~elkan/250A/bayesnets.pdf\n",
        "\n",
        "[3] Cooper, G. 1990, ‘The Computational Complexity of Probabilistic Inference Using Bayesian Belief Networks’, Artificial Intelligence, Vol. 42, Issues no. 2–3, pp. 396.\n",
        "\n",
        "[4] Cooper, G. 1990, ‘The Computational Complexity of Probabilistic Inference Using Bayesian Belief Networks’, Artificial Intelligence, Vol. 42, Issues no. 2–3, pp. 403.\n",
        "\n",
        "[5] Cooper, G. 1990, ‘The Computational Complexity of Probabilistic Inference Using Bayesian Belief Networks’, Artificial Intelligence, Vol. 42, Issues no. 2–3, pp. 404."
      ]
    }
  ]
}
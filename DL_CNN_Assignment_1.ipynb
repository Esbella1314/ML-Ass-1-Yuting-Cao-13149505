{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL-CNN Assignment 1",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPG4Sh2DPNm/W+1vkF5uNcu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Esbella1314/ML-Ass-1-Yuting-Cao-13149505/blob/master/DL_CNN_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIFQ2Lub5TSQ",
        "colab_type": "text"
      },
      "source": [
        "#Deep Learning and Convolutional Neural Network Assignment 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HHk3VN45VHS",
        "colab_type": "text"
      },
      "source": [
        "Subject Name:\t\t42028 Deep Learning and Convolutional Neural Network\n",
        "\n",
        "Students Name:     Yuting Cao                   \n",
        "Student ID:        13149505                \n",
        "Student Email:     yuting.cao@student.uts.edu.au\n",
        "\n",
        "\n",
        "Github Link: https://github.com/Esbella1314/ML-Ass-1-Yuting-Cao-13149505/blob/master/A3_ReportDraft.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR7zza0l5xJ8",
        "colab_type": "text"
      },
      "source": [
        "# 1 Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypYfRur97K9I",
        "colab_type": "text"
      },
      "source": [
        "###Step 1: Import Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3IMiuhP7QSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import feature # This pacakge is used for LBP feature extraction\n",
        "from sklearn import svm # This pacakge is used for svm classification\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "%matplotlib inline\n",
        "import cv2\n",
        "import seaborn as sns # This pacakge is used for better visualization of data (e.g confusion matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBpP2ybW7cFw",
        "colab_type": "text"
      },
      "source": [
        "### Step 2: Mount the Google Drive to access the Fashion MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOPsIPqc7iUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5k5ystc7xpc",
        "colab_type": "text"
      },
      "source": [
        "### Step 3: Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxKm672e8BMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_mnist(path, kind='train'):\n",
        "    import os\n",
        "    import gzip\n",
        "    import numpy as np\n",
        "\n",
        "    \"\"\"Load MNIST data from `path`\"\"\"\n",
        "    labels_path = os.path.join(path,\n",
        "                               '%s-labels-idx1-ubyte.gz'\n",
        "                               % kind)\n",
        "    images_path = os.path.join(path,\n",
        "                               '%s-images-idx3-ubyte.gz'\n",
        "                               % kind)\n",
        "\n",
        "    with gzip.open(labels_path, 'rb') as lbpath:\n",
        "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
        "                               offset=8)\n",
        "\n",
        "    with gzip.open(images_path, 'rb') as imgpath:\n",
        "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
        "                               offset=16).reshape(len(labels), 784)\n",
        "\n",
        "    return images, labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCdfoPFA8TZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/gdrive/My Drive/Deep Learning Assignment 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-PdjsiE8fdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOeor3sR8mVj",
        "colab_type": "text"
      },
      "source": [
        "### Step 4: Use the Utility Function to Load the Dataset and Split it into Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgPmweG-8x6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = load_mnist('/content/gdrive/My Drive/42028-DL-CNN-2020/Week3-Lab3/data/fashion', kind='train')\n",
        "X_test, y_test = load_mnist('/content/gdrive/My Drive/42028-DL-CNN-2020/Week3-Lab3/data/fashion', kind='t10k')\n",
        "# initialize the label names from Fashion MNIST github repository\n",
        "\n",
        "labelNames = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\n",
        "\t\"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kqSkaIg81Kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The 28X28 images are flattened to feature vector of size 784\n",
        "# There are 60,000 training examples in the training dataset\n",
        "# There are 10,000 test sample in the testing dataset\n",
        "print(np.shape(X_train))\n",
        "print(np.shape(X_test))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPoOiPQN852R",
        "colab_type": "text"
      },
      "source": [
        "### Step 5: Reshaping the Feature Vector Back into the 28X28 Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRYr4oOS9CUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=X_train.reshape(-1,28,28)\n",
        "X_test=X_test.reshape(-1,28,28)\n",
        "\n",
        "# print the size of the result reshaped train and test data splits\n",
        "\n",
        "print(\"Train dataset after reshaping:{}\".format(np.shape(X_train)))\n",
        "print(\"Test dataset after reshaping :{}\".format(np.shape(X_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-OUjosP9SFC",
        "colab_type": "text"
      },
      "source": [
        "### Step 6: Visualization of Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCiKNGPu9ZT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# view few images and print its corresponding label\n",
        "img_index = 10\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(2,2,1)\n",
        "ax1.axis('off')\n",
        "ax1.imshow(X_train[img_index])\n",
        "print(labelNames[y_train[img_index]])\n",
        "\n",
        "ax2 = fig.add_subplot(2,2,2)\n",
        "ax2.axis('off')\n",
        "img_index = 1000\n",
        "ax2.imshow(X_train[img_index])\n",
        "print(labelNames[y_train[img_index]])\n",
        "\n",
        "ax2 = fig.add_subplot(2,2,3)\n",
        "ax2.axis('off')\n",
        "img_index = 20000\n",
        "ax2.imshow(X_train[img_index])\n",
        "print(labelNames[y_train[img_index]])\n",
        "\n",
        "ax2 = fig.add_subplot(2,2,4)\n",
        "ax2.axis('off')\n",
        "img_index = 30000\n",
        "ax2.imshow(X_train[img_index])\n",
        "print(labelNames[y_train[img_index]])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iftpPN7_MQP",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 Histogram-of-Oriented"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hSzsj-FAR0r",
        "colab_type": "text"
      },
      "source": [
        "### Step 7: Histogram-of-Oriented Gradient (HOG) Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpVWCLpf_OU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize the data matrix and labels\n",
        "print(\"Extracting features from training dataset...\")\n",
        "data_train = []\n",
        "labels_train = []\n",
        "\n",
        "# loop over the training images\n",
        "for img_index in range(len(X_train)):\n",
        "  # load the image, and extract HOG features\n",
        "  image = (X_train[img_index])\n",
        "  #gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  H = feature.hog(image, orientations=9, pixels_per_cell=(10, 10),\n",
        "                  cells_per_block=(2, 2), transform_sqrt=True, block_norm=\"L2-Hys\")\n",
        " \n",
        "  # update the data and labels\n",
        "  data_train.append(H)\n",
        "  labels_train.append(y_train[img_index])\n",
        "\n",
        "print(np.shape(data_train))\n",
        "print(np.shape(labels_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zphZJk3uAkXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VL13WqBF_C15",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Local Binary Patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYXfhHUz9zQM",
        "colab_type": "text"
      },
      "source": [
        "### Step 8: Local Binary Patterns (LBP) Class Definition for LBP Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaXGbsCl972O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LocalBinaryPatterns:\n",
        "\tdef __init__(self, numPoints, radius):\n",
        "\t\t# store the number of points and radius\n",
        "\t\tself.numPoints = numPoints\n",
        "\t\tself.radius = radius\n",
        " \n",
        "\tdef LBPfeatures(self, image, eps=1e-7):\n",
        "\t\t# compute the Local Binary Pattern representation\n",
        "\t\t# of the image, and then use the LBP representation\n",
        "\t\t# to build the histogram of patterns\n",
        "\t\tlbp = feature.local_binary_pattern(image, self.numPoints,\n",
        "\t\t\tself.radius, method=\"uniform\")\n",
        "    # Form the histogram\n",
        "\t\t(hist, _) = np.histogram(lbp.ravel(),\n",
        "\t\t\tbins=np.arange(0, self.numPoints + 3),\n",
        "\t\t\trange=(0, self.numPoints + 2))\n",
        " \n",
        "\t\t# normalize the histogram\n",
        "\t\thist = hist.astype(\"float\")\n",
        "\t\thist /= (hist.sum() + eps)\n",
        " \n",
        "\t\t# return the histogram of Local Binary Patterns\n",
        "\t\treturn hist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KWP92X69_Cl",
        "colab_type": "text"
      },
      "source": [
        "### Step 9: LBP Feature Extraction for the Whole Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDeCr6ov-T8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an object of LocalBinaryPatterns class and initial the parameters.\n",
        "desc = LocalBinaryPatterns(24, 8)\n",
        "data_train = []\n",
        "labels_train = []\n",
        "\n",
        "# loop over the training images\n",
        "for img_index in range(len(X_train)):\n",
        "\t# load the image, convert it to grayscale, and extract LBP features\n",
        "\timage = (X_train[img_index])\n",
        "\thist = desc.LBPfeatures(image)\n",
        " \n",
        "\t# extract the label from the image path, then update the\n",
        "\t# label and data lists\n",
        "\tlabels_train.append(y_train[img_index])\n",
        "\tdata_train.append(hist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lm09EeLGDcGI",
        "colab_type": "text"
      },
      "source": [
        "#2 Experimental Settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS5l3zhWDq3q",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVhfSSanDuPA",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48TKBPqPDyIS",
        "colab_type": "text"
      },
      "source": [
        "## 2.3 ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVGPntzoD2GG",
        "colab_type": "text"
      },
      "source": [
        "# 3 Experimental Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RhnbQkrEBg_",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 Test Dataset Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3i2-j-BEqsw",
        "colab_type": "text"
      },
      "source": [
        "### Step xx: Test Set Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6a8MDgZD_9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test set Accuracy\n",
        "accuracy = metrics.accuracy_score(y_test, predict_test)\n",
        "print(\"Accuracy on test dataset:\",accuracy)\n",
        "# Expected test Accuracy 0.75"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48HReE1JEaUM",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Kw_R0CoEwgB",
        "colab_type": "text"
      },
      "source": [
        "### Step xx: Plot the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZB137BAEgmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the confusion matrix\n",
        "cm  = metrics.confusion_matrix(y_test, predict_test)\n",
        "print(cm)\n",
        "\n",
        "# Plot confusion matrix using seaborn library\n",
        "plt.figure(figsize=(9,9))\n",
        "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
        "plt.ylabel('Actual label');\n",
        "plt.xlabel('Predicted label');\n",
        "all_sample_title = 'Accuracy Score: {0}'.format(accuracy)\n",
        "plt.title(all_sample_title, size = 15);\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eq9POdtbE4LR",
        "colab_type": "text"
      },
      "source": [
        "### Step xx: Visualization of Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHHEhRvhE_KR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = []\n",
        "orig_labels=[]\n",
        "# randomly select a few testing fashion items\n",
        "for i in np.random.choice(np.arange(0, len(y_test)), size=(16,)):\n",
        "  # classify the clothing\n",
        "  test_img = (X_test[i])\n",
        "  H1 = feature.hog(test_img, orientations=9, pixels_per_cell=(10, 10),\n",
        "                  cells_per_block=(2, 2), transform_sqrt=True, block_norm=\"L2-Hys\")\n",
        "  pred = model.predict(H1.reshape(1, -1))[0]\n",
        "  #prediction = model.predict(test_img.reshape(1, -1))\n",
        "  label = labelNames[pred]\n",
        "  orig_labels.append(labelNames[y_test[i]])\n",
        "  color = (0, 255, 0)\n",
        "  test_img = cv2.merge([test_img] * 3)\n",
        "  test_img = cv2.resize(test_img, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
        "  cv2.putText(test_img, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.50, color, 2)\n",
        "  images.append(test_img)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS7aTnSPFCuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "orig_labels[1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0h5apM6FHTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(2,2,1)\n",
        "ax1.imshow(images[1])\n",
        "print(orig_labels[1])\n",
        "ax2 = fig.add_subplot(2,2,2)\n",
        "ax2.imshow(images[2])\n",
        "print(orig_labels[2])\n",
        "ax3 = fig.add_subplot(2,2,3)\n",
        "ax3.imshow(images[3])\n",
        "print(orig_labels[3])\n",
        "ax4 = fig.add_subplot(2,2,4)\n",
        "ax4.imshow(images[4])\n",
        "print(orig_labels[4])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}